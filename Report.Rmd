---
title: "Report"
author: "FÃ¡bio Teixeira, Miguel Ferreira, Vanessa Silva"
date: "20 de Dezembro de 2016"
output: html_document
---

#First task:

##Data import and clean-up

###Setting the working directory

Download the file "crime.xls" to the directory where you are going to work. Alternatively, if you want to change the current directory, do:

```{r, eval=FALSE}
setwd(dir)
```

And to view the current directory:

```{r}
getwd()
```

###Import the data into an appropriate R format:

Note: If you do not have Perl installed on Windows, download it [here](http://www.activestate.com/activeperl/downloads).

```{r, message=FALSE, warning=FALSE, results='hide'}
#Install the necessary packages
install.packages("gdata")
install.packages("lubridate")
install.packages("xts")
install.packages("dplyr")
install.packages("DMwR")

#Load the packages
library(gdata)
library(lubridate)
library(xts)
library(dplyr)
library(stringr)
library(DMwR)
library(class)

perldir <- Sys.which("perl")

fc <- "crime.xls" 
dat <- read.xls(fc, sheet = 1, header = TRUE, verbose=FALSE, perl=perldir, na.strings = "UNK")
dat$BlockRange <- as.character(dat$BlockRange)
dat$StreetName <- as.character(dat$StreetName)
dat$Type <- as.character(dat$Type)
dat$Suffix <- as.character(dat$Suffix)
```

###Check whether any data clean-up and/or pre-processing steps are necessary.
The Offense Types found on the data set are:
```{r}
unique(dat$Offense.Type)
dat[dat$Offense.Type == 1,]
```

We identified an instance where the `Offense.Type` column does not have a valid value. However, it is a registered crime that quite possibly happened, and although it may not help predicting which crimes may occur, it will surely help predicting how many crimes per beat will occur.
Thus we perform a "cleaning" of the same.

```{r}
#dat_clean <- dat[-(dat$Offense.Type == 1), ]
#dat <- subset(dat, dat$Offense.Type != 1)
```

All dates have a valid format:
```{r}
dat[!grep("^[0-9]{4}-[0-9]{2}-[0-9]{2}$", dat$Date),]
```

All hours have a valid format:
```{r}
dat[dat$Hour < 0 | dat$Hour > 23,]
dat[!grep("^[0-9]{2}$", dat$Hour),]
```
Some anomalies (unknown values) were found on the `Beat` column:
```{r}
unique(dat$Beat)
nrow(dat[is.na(dat$Beat),])
```

The `Beat` column is rather important since the purpose of the prediction model is given a beat and a time of the day, predict how many crimes will occur. Luckily, there are not many invalid `Beat` cells.

Based on Hounton Police beat map, we can reconstruct manually the `Beat` cells using the street name and block range.
![](hpd_beat_map.png)

However, using Google Maps API and Data Science Toolkit providers for the package `ggmap` we were able to obtain GPS coordinates for the locations of each crime. This allows us to reconstruct the `Beat` column using the k-nearest neighbours of the coordinates column.

```{r}
load("gps.RData")
incomplete <- is.na(dat$Beat)
tr <- gps[!incomplete,1:2]
ts <- gps[incomplete,1:2]
dat$Beat[incomplete] <- knn(tr, ts, dat$Beat[!incomplete], k = 3)
```

Some anomalies (unknown values) were found on the `BlockRange` column:
```{r}
nrow(dat[is.na(dat$BlockRange),])
```
To solve it, we replaced the invalid cells for the central value of the `BlockRange` column:
```{r}
incomplete <- is.na(dat$BlockRange)
dat$BlockRange[incomplete] <- centralValue(dat$BlockRange)
```
Some anomalies (worthless) were found on the `Type` column:
```{r}
unique(dat$Type)
nrow(dat[dat$Type == "-",])
```
Some anomalies (worthless) were found on the `Suffix` column:
```{r}
unique(dat$Suffix)
nrow(dat[dat$Suffix == "-",])
```
All offenses were counted:
```{r}
unique(dat$X..offenses)
```

For each anomaly detected we have 3 options:

- Remove lines containing invalid data.
- Substitute invalid cells by a central measure of the cell.
- Substitute invalid cells by an average over the k-nearest neighbours of its line on the data set.

#Second task:

##Data exploratory analysis
Summarize and visualize the data in ways that we find useful for the police (look for interesting questions the police may have about the data and provide the answers, or use textual summaries or data visualization).

```{r}
dat <- tbl_df(dat)

#View the data per hour
datxts <- xts(dat, ymd_h(paste(dat$Date,' ',dat$Hour)))

#Split the data into 3 categories
i1 <- filter(dat, 8 <= dat$Hour, dat$Hour < 12)
i2 <- filter(dat, 12 <= dat$Hour, dat$Hour < 19)
i3 <- filter(dat, (19 <= dat$Hour & dat$Hour <= 23) | (0 <= dat$Hour & dat$Hour < 8))

#How many Offenses are made per interval in each category
sum1 <- group_by(i1, Beat) %>% summarise(num=sum(X..offenses))
sum2 <- group_by(i2, Beat) %>% summarise(num=sum(X..offenses))
sum3 <- group_by(i3, Beat) %>% summarise(num=sum(X..offenses))

#How many offenses are made per offense type
sum4 <- group_by(dat, Offense.Type) %>% summarise(num=sum(X..offenses))
plot(sum4$num ~ sum4$Offense.Type, xlab = "Offense.Type", ylab = "Num", main = "Number of offenses per offense type")

#How many offenses are made per offense type in each beat
sum5 <- group_by(dat, Offense.Type, Beat) %>% summarise(num=sum(X..offenses))
```
Some data summarization:
```{r}
dat %>% summarise(avg.Off=mean(dat$X..offenses),
                  cen.OffTp=centralValue(dat$Offense.Type),
                  cen.StrNm=centralValue(dat$StreetName))
```

```{r}
barplot(c(sum(sum1$num), sum(sum2$num), sum(sum3$num)), names.arg = c("8-12", "12-19", "19-8"), main = "Total crimes over time intervals")
```

```{r}
beat <- group_by(dat, Beat) %>% summarise(num=sum(X..offenses))
most <- head(arrange(beat,desc(num)))
barplot(most$num, names.arg=most$Beat, main="Beats with most crimes")
```

```{r}
least <- head(arrange(beat, num))
barplot(least$num, names.arg=least$Beat, main="Beats with least crimes")
```

```{r}
boxplot(beat$num, main="Distribution of number of crimes per beat")
```

```{r}
offenses <- group_by(dat, Offense.Type) %>%
  filter(Offense.Type != 1) %>% summarize(total=sum(X..offenses))
barplot(offenses$total, names.arg=offenses$Offense.Type,
        main="Number of occurences per crime type")
```

#Third task:

##Predictive modeling
###Set a prediction task that can help police respond to their operational objective. 

```{r}
```

###Use the available data to select and get a good model for this task.

```{r}

```

###Give a justification for the suggested model.
